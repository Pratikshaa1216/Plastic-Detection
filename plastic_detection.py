# -*- coding: utf-8 -*-
"""Plastic Detection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1IejDfBuyzq-Yn-L2RNwRJYlENDi2GAww

# Load Dataset

Initializing a few parameters required for the image dataset preprocessing.
"""



!unzip data.zip

# Commented out IPython magic to ensure Python compatibility.
import matplotlib.pyplot as plt
# %matplotlib inline
import pandas as pd
import numpy as np
import PIL
from PIL import Image
from skimage.color import rgb2gray
from scipy import ndimage as ndi
import cv2
import os
from os import listdir
from sklearn.utils import shuffle
import tensorflow as tf
import keras
from keras.models import Sequential, load_model
from keras.layers import Dense, Activation, Conv2D, MaxPooling2D, Flatten, Dropout, BatchNormalization,Input
from keras import Model
from tensorflow.keras.optimizers import SGD
from keras import regularizers
from keras.callbacks import ModelCheckpoint

# Commented out IPython magic to ensure Python compatibility.
# %tensorflow_version 2.x
import tensorflow as tf
device_name = tf.test.gpu_device_name()
if device_name != '/device:GPU:0':
  raise SystemError('GPU device not found')
print('Found GPU at: {}'.format(device_name))

"""We use the function `convert_image_to_array` to resize an image to the size `DEFAULT_IMAGE_SIZE` we defined above.

"""

directory_root = '/content/Data Set/train'
print("[INFO] Loading Training images...")
root_dir = listdir(directory_root)
print("\nTotal Folder : ",len(root_dir))

for plant_folder in root_dir :
  print("\n\nLoading Folder : ",plant_folder)
  plant_disease_folder_list = listdir(f"{directory_root}/{plant_folder}")
  total_images = len(plant_disease_folder_list)
  print("Total Images found : ",total_images)

directory_root = '/content/Data Set/val'
print("[INFO] Loading Training images...")
root_dir = listdir(directory_root)
print("\nTotal Folder : ",len(root_dir))

for plant_folder in root_dir :
  print("\n\nLoading Folder : ",plant_folder)
  plant_disease_folder_list = listdir(f"{directory_root}/{plant_folder}")
  total_images = len(plant_disease_folder_list)
  print("Total Images found : ",total_images)

list_classes = os.listdir('/content/Data Set/train')
list_classes





"""<h1> Image Preprocessing </h1>"""

# image preprocessing
from keras.preprocessing.image import ImageDataGenerator

train_datagen = ImageDataGenerator()
                                  #  rescale=1./255,
                                  #  shear_range=0.2,
                                  #  zoom_range=0.2,
                                  #  width_shift_range=0.2,
                                  #  height_shift_range=0.2,
                                  #  fill_mode='nearest')

test_datagen = ImageDataGenerator()
# rescale=1./255

batch_size = 256
base_dir = '/content/Data Set'

training_set = train_datagen.flow_from_directory(base_dir+'/train',
                                                 batch_size=batch_size,
                                                 class_mode='categorical')

test_set = test_datagen.flow_from_directory(base_dir+'/val',
                                            batch_size=batch_size,
                                            class_mode='categorical')

class_dict = training_set.class_indices
print(class_dict)

li = list(class_dict.keys())
print(li)

train_num = training_set.samples
test_num = test_set.samples

train_num, test_num

"""

```
# This is formatted as code
```

# Augment and Split Dataset <h1> VGG 16 Model Architecture </h1>"""

from keras.applications.vgg16 import VGG16

in_shape=(256, 256, 3)
out_shape=4

vgg_model = VGG16(include_top=False, input_shape=in_shape)
for layer in vgg_model.layers:
  layer.trainable = False

# allow last vgg block to be trainable
vgg_model.get_layer('block5_conv1').trainable = True
vgg_model.get_layer('block5_conv2').trainable = True
vgg_model.get_layer('block5_conv3').trainable = True
vgg_model.get_layer('block5_pool').trainable = True

# add new classifier layers
flat1 = Flatten()(vgg_model.layers[-1].output)
fcon1 = Dense(4096, activation='relu', kernel_initializer='he_uniform')(flat1)
fdrop1 = Dropout(0.25)(fcon1)
fbn1 = BatchNormalization()(fdrop1)
fcon2 = Dense(4096, activation='relu', kernel_initializer='he_uniform')(fbn1)
fdrop2 = Dropout(0.25)(fcon2)
fbn2 = BatchNormalization()(fdrop2)
output = Dense(out_shape, activation='softmax')(fbn2)

# define new model
vgg_model = Model(inputs=vgg_model.inputs, outputs=output)

# compile model
opt = SGD(lr=0.01, momentum=0.9,decay=0.005)
vgg_model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])

vgg_model.summary()

"""# Build Model

Defining the hyperparameters of the plastic_detection classification model.
"""

# checkpoint
from keras.callbacks import ModelCheckpoint
weightpath = "VGG_Best_Weights.hdf5"
checkpoint = ModelCheckpoint(weightpath, monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=True, mode='max')
callbacks_list = [checkpoint]



"""# Train Model


```
# This is formatted as code
```


"""

#fitting images to AlexNet
history = vgg_model.fit_generator(training_set,
                         steps_per_epoch=train_num//batch_size,
                         validation_data=test_set,
                         epochs=30,
                         validation_steps=test_num//batch_size,
                         callbacks=callbacks_list)
#saving model
filepath= "VGGModel.hdf5"
vgg_model.save(filepath)

"""**bold text**# Train Model

We initialize Adam optimizer with learning rate and decay parameters. 

Also, we choose the type of loss and metrics for the model and compile it for training.
"""

#plotting training values
import matplotlib.pyplot as plt
import seaborn as sns
sns.set()

acc = history.history['accuracy']
loss = history.history['loss']
epochs = range(1, len(loss) + 1)

#accuracy plot
plt.plot(epochs, acc, color='green', label='Training Accuracy')
plt.title('Training and Validation Accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend()

plt.figure()
#loss plot
plt.plot(epochs, loss, color='pink', label='Training Loss')
plt.title('Training and Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()

plt.show()

list_classes

from keras.preprocessing import image
li = list_classes
def process_img(image_path, model):
  # predicting an image
  new_img = image.load_img(image_path, target_size=(256, 256))
  img = image.img_to_array(new_img)
  img = np.expand_dims(img, axis=0)
  img = img/255

  print("Following is our prediction:")
  prediction = model.predict(img)
  print(prediction)
  # decode the results into a list of tuples (class, description, probability)
  # (one such list for each sample in the batch)
  d = prediction.flatten()
  j = d.max()
  for index,item in enumerate(d):
      if item == j:
          class_name = li[index]
          print(class_name)

          plt.figure(figsize = (4,4))
          plt.imshow(new_img)
          plt.axis('off')
          plt.title(class_name)
          plt.show()

VGGModel = load_model("VGGModel.hdf5")

while True:
    path = input('\n\n\nEnter Image Path : ').replace('"',"")
    process_img(path, VGGModel)

VGGModel.evaluate(test_set)



